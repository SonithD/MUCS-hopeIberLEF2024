{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of-_XEJLTRSm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_train=pd.read_csv('train (2).csv')\n",
        "df_val=pd.read_csv('val (4).csv')\n",
        "df_test=pd.read_csv('Task2_ES_test_no_label (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfmD1fbrEIpO",
        "outputId": "346eb0ec-db39-4428-bd25-5abd71c842bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>binary</th>\n",
              "      <th>multiclass</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mientras me persigno y le rezo a la Virgen del...</td>\n",
              "      <td>Not Hope</td>\n",
              "      <td>Not Hope</td>\n",
              "      <td>5533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No.. Yo ya no estoy para esperar.. Ni para rog...</td>\n",
              "      <td>Not Hope</td>\n",
              "      <td>Not Hope</td>\n",
              "      <td>549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Creo que estamos ante el mejor episodio de est...</td>\n",
              "      <td>Hope</td>\n",
              "      <td>Generalized Hope</td>\n",
              "      <td>4350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bueno ojal√° q cuando llegue este fin de semana...</td>\n",
              "      <td>Hope</td>\n",
              "      <td>Realistic Hope</td>\n",
              "      <td>3593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#USER# #USER# Marcos de boludo no tiene un pel...</td>\n",
              "      <td>Not Hope</td>\n",
              "      <td>Not Hope</td>\n",
              "      <td>770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text    binary  \\\n",
              "0  Mientras me persigno y le rezo a la Virgen del...  Not Hope   \n",
              "1  No.. Yo ya no estoy para esperar.. Ni para rog...  Not Hope   \n",
              "2  Creo que estamos ante el mejor episodio de est...      Hope   \n",
              "3  Bueno ojal√° q cuando llegue este fin de semana...      Hope   \n",
              "4  #USER# #USER# Marcos de boludo no tiene un pel...  Not Hope   \n",
              "\n",
              "         multiclass    id  \n",
              "0          Not Hope  5533  \n",
              "1          Not Hope   549  \n",
              "2  Generalized Hope  4350  \n",
              "3    Realistic Hope  3593  \n",
              "4          Not Hope   770  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezzrLpEDEIpO",
        "outputId": "ced9b4b2-6062-4ba2-f9d5-9ba8fa6f0e27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Not Hope            4701\n",
              "Generalized Hope    1151\n",
              "Unrealistic Hope     546\n",
              "Realistic Hope       505\n",
              "Name: multiclass, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['multiclass'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyDqPUizEIpO",
        "outputId": "291c9b20-7baa-4149-db71-0112f511be43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: num2words in c:\\users\\ccl\\anaconda3\\lib\\site-packages (0.5.13)\n",
            "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\ccl\\anaconda3\\lib\\site-packages (from num2words) (0.6.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install num2words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjp93xqgEIpO"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import emoji\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import contractions\n",
        "\n",
        "def preprocess(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Convert emojis to textual representation\n",
        "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "    text = text.replace(\"_\", \"  \")\n",
        "\n",
        "    # Remove special characters and punctuation\n",
        "    exclude = set(string.punctuation + 'üè≥Ô∏è‚Äç‚ößÔ∏èüîç¬ø')\n",
        "    text = ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    # Fix contractions\n",
        "    text = contractions.fix(text, slang=True)\n",
        "\n",
        "    # Remove usernames\n",
        "    text = re.sub('@[a-zA-Z0-9_]*', '', text)\n",
        "\n",
        "    # Replace '$' with 'dollar'\n",
        "    text = text.replace('$', ' dollar ')\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    english_stopwords = stopwords.words('spanish')\n",
        "    text = [t for t in tokens if t not in english_stopwords]\n",
        "    text = \" \".join(text)\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRSrMW0CEIpP",
        "outputId": "35fd9f23-f334-44ce-ba38-4e103acdeaa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: inflect in c:\\users\\ccl\\anaconda3\\lib\\site-packages (7.2.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in c:\\users\\ccl\\anaconda3\\lib\\site-packages (from inflect) (4.2.1)\n",
            "Requirement already satisfied: more-itertools in c:\\users\\ccl\\anaconda3\\lib\\site-packages (from inflect) (10.2.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\ccl\\anaconda3\\lib\\site-packages (from inflect) (4.11.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\ccl\\anaconda3\\lib\\site-packages (from typeguard>=4.0.1->inflect) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\ccl\\anaconda3\\lib\\site-packages (from importlib-metadata>=3.6->typeguard>=4.0.1->inflect) (3.8.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ccl\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install inflect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Emk27UyTEIpP"
      },
      "outputs": [],
      "source": [
        "import inflect\n",
        "p = inflect.engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k21DXB4WEIpP"
      },
      "outputs": [],
      "source": [
        "def number_to_words(text):\n",
        "    return ' '.join(p.number_to_words(token) if token.isdigit() else token for token in text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOc5_3bPEIpP"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords, wordnet\n",
        "\n",
        "import emoji\n",
        "#import demoji\n",
        "#demoji.download_codes()\n",
        "def emo(text):\n",
        "  temp=emoji.demojize(text,delimiters=(\" \",\" \"))\n",
        "  temp=temp.replace(\"_\",\"  \")\n",
        "  return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdoQliH8EIpP"
      },
      "outputs": [],
      "source": [
        "df_train['clean_text'] = df_train['text'].apply(lambda x:emo(x))\n",
        "#df_train[\"clean_text\"]=df_train['clean_text'].apply(lambda X: number_to_words(X))\n",
        "df_train[\"clean_text\"]=df_train['clean_text'].apply(lambda X: preprocess(X))\n",
        "\n",
        "df_val['clean_text'] = df_val['text'].apply(lambda x:emo(x))\n",
        "#df_val[\"clean_text\"]=df_val['clean_text'].apply(lambda X: number_to_words(X))\n",
        "df_val[\"clean_text\"]=df_val['clean_text'].apply(lambda X: preprocess(X))\n",
        "\n",
        "\n",
        "df_test['clean_text'] = df_test['text'].apply(lambda x:emo(x))\n",
        "#df_test[\"clean_text\"]=df_test['clean_text'].apply(lambda X: number_to_words(X))\n",
        "df_test[\"clean_text\"]=df_test['clean_text'].apply(lambda X: preprocess(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuHTldzSZJFr"
      },
      "outputs": [],
      "source": [
        "x_train=df_train['clean_text'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YnRKjsnEIpP"
      },
      "outputs": [],
      "source": [
        "x_test=df_test['clean_text'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dt_32Lx5EIpP"
      },
      "outputs": [],
      "source": [
        "x_val=df_val['clean_text'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWIk9ueuUCRa"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(df_train['multiclass'])\n",
        "y_val =label_encoder.transform(df_val['multiclass'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuBHztWDUGWB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm #dont run this\n",
        "benvocab = []\n",
        "embedding_index_ben = {}\n",
        "f = open('wiki.es.align.vec',encoding='utf-8')\n",
        "for line in f:\n",
        "        values = line.rstrip().split(' ')\n",
        "        word = values[0]\n",
        "        benvocab.append(word)\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index_ben[word] = coefs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82rcYs_jUKty"
      },
      "outputs": [],
      "source": [
        "def get_vectors(sentence):# dont run\n",
        "    sentvec = np.zeros(300)\n",
        "    zeros = np.zeros(300)\n",
        "\n",
        "    for word in sentence.split():\n",
        "        if word in benvocab:\n",
        "             temp = embedding_index_ben[word]\n",
        "        else: temp = zeros\n",
        "        # print('word : ', word, ' ttt : ', temp)\n",
        "        sentvec += temp\n",
        "\n",
        "    sentvec = sentvec / len(sentence.split())\n",
        "    return sentvec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDqj9e-UamGU"
      },
      "outputs": [],
      "source": [
        "# X=pd.DataFrame(x)\n",
        "# Y=pd.DataFrame(y)\n",
        "\n",
        "# # X_test11=pd.DataFrame(x_test)\n",
        "# # y_test11=pd.DataFrame(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMpJA0rJRy4x"
      },
      "outputs": [],
      "source": [
        "# X=X.rename(columns={0:'text'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gaD4x9dSJ0B"
      },
      "outputs": [],
      "source": [
        "# Y=Y.rename(columns={0:'label'})\n",
        "# X_test11=X_test11.rename(columns={0:'text'})\n",
        "# y_test11=y_test11.rename(columns={0:'label'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T3ozd8zavJF"
      },
      "outputs": [],
      "source": [
        "# df=pd.concat([X,Y], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9HvB9Qtbk_L"
      },
      "outputs": [],
      "source": [
        "#df_train=pd.concat([X_train11,y_train11], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28utcWm5a2sU",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIVnpbyfcYGU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ5sblIWVZTr"
      },
      "outputs": [],
      "source": [
        "df_train['vec'] = df_train['clean_text'].apply(lambda x:get_vectors(x))#dont run this\n",
        "df_val['vec'] = df_val['clean_text'].apply(lambda x:get_vectors(x))\n",
        "df_test['vec'] = df_test['clean_text'].apply(lambda x:get_vectors(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKAOK6SLqTMq"
      },
      "outputs": [],
      "source": [
        "# import pickle #dont run this\n",
        "# with open('/content/drive/MyDrive/vectrain_file.pkl', 'wb') as f:  # open a text file\n",
        "#     pickle.dump(df['vec'], f) # serialize the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlrL39jASdwX"
      },
      "outputs": [],
      "source": [
        "#xtest = df_test['text'].apply(lambda x:get_vectors(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzYnjcpAf8AR"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# with open('/content/drive/MyDrive/vectrain_file.pkl', 'rb') as f:\n",
        "\n",
        "#     train_loaded = pickle.load(f) # deserialize using load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npXEUjCJUrky"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm, tree\n",
        "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uudJiUTsUuBy"
      },
      "outputs": [],
      "source": [
        "classifiers=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ35mxemEIpR"
      },
      "outputs": [],
      "source": [
        "SVM = svm.SVC(probability=True, kernel=\"rbf\", class_weight=\"balanced\")\n",
        "classifiers.append(SVM)\n",
        "svc =  LinearSVC(class_weight='balanced')\n",
        "classifiers.append(svc)\n",
        "RFC = RandomForestClassifier(n_estimators=200, random_state=0)\n",
        "classifiers.append(RFC)\n",
        "LR = LogisticRegression(random_state=0, solver='lbfgs',\n",
        "                            multi_class='multinomial')\n",
        "classifiers.append(LR)\n",
        "MLP = MLPClassifier()\n",
        "classifiers.append(MLP)\n",
        "kNNeigh = KNeighborsClassifier()\n",
        "classifiers.append(kNNeigh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZJQW50hUv_S"
      },
      "outputs": [],
      "source": [
        "# # MNB = MultinomialNB()\n",
        "# # classifiers.append(MNB)\n",
        "# gbc = GradientBoostingClassifier()\n",
        "# classifiers.append(gbc)\n",
        "\n",
        "# classifiers.append(gbc)\n",
        "# SVM = svm.SVC()\n",
        "# classifiers.append(SVM)\n",
        "# DT = tree.DecisionTreeClassifier()\n",
        "# classifiers.append(DT)\n",
        "# RFC = RandomForestClassifier()\n",
        "# classifiers.append(RFC)\n",
        "# LR = LogisticRegression()\n",
        "# classifiers.append(LR)\n",
        "# #MLP = MLPClassifier(random_state=1, max_iter=300)\n",
        "# # MLP = MLPClassifier()\n",
        "# # classifiers.append(MLP)\n",
        "# Percpt= Perceptron()\n",
        "# classifiers.append(Percpt)\n",
        "# # svc=SVC()\n",
        "# # classifiers.append(svc)\n",
        "# kNNeigh = KNeighborsClassifier()#p:n_neighbors=3\n",
        "# classifiers.append(kNNeigh)\n",
        "# xgb=XGBClassifier()\n",
        "# classifiers.append(xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmAOZcA6dRCj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "QYTNrnAkdTCK",
        "outputId": "4af439ee-a941-49a1-de1a-34225bd14c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of SVC(class_weight='balanced', probability=True) is 0.6060869565217392\n",
            "Confusion Matrix of SVC(class_weight='balanced', probability=True) is [[103  42  21  20]\n",
            " [107 531  64  97]\n",
            " [ 14  26  23  11]\n",
            " [ 14  19  18  40]]\n",
            "Classificationreport is  of SVC(class_weight='balanced', probability=True) is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.55      0.49       186\n",
            "           1       0.86      0.66      0.75       799\n",
            "           2       0.18      0.31      0.23        74\n",
            "           3       0.24      0.44      0.31        91\n",
            "\n",
            "    accuracy                           0.61      1150\n",
            "   macro avg       0.43      0.49      0.44      1150\n",
            "weighted avg       0.70      0.61      0.64      1150\n",
            "\n",
            "Accuracy of LinearSVC(class_weight='balanced') is 0.6947826086956522\n",
            "Confusion Matrix of LinearSVC(class_weight='balanced') is [[ 95  67   9  15]\n",
            " [ 72 661  28  38]\n",
            " [ 12  40  14   8]\n",
            " [  9  37  16  29]]\n",
            "Classificationreport is  of LinearSVC(class_weight='balanced') is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.51      0.51       186\n",
            "           1       0.82      0.83      0.82       799\n",
            "           2       0.21      0.19      0.20        74\n",
            "           3       0.32      0.32      0.32        91\n",
            "\n",
            "    accuracy                           0.69      1150\n",
            "   macro avg       0.46      0.46      0.46      1150\n",
            "weighted avg       0.69      0.69      0.69      1150\n",
            "\n",
            "Accuracy of RandomForestClassifier(n_estimators=200, random_state=0) is 0.7086956521739131\n",
            "Confusion Matrix of RandomForestClassifier(n_estimators=200, random_state=0) is [[ 26 160   0   0]\n",
            " [  9 789   0   1]\n",
            " [  2  72   0   0]\n",
            " [  1  90   0   0]]\n",
            "Classificationreport is  of RandomForestClassifier(n_estimators=200, random_state=0) is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.14      0.23       186\n",
            "           1       0.71      0.99      0.83       799\n",
            "           2       0.00      0.00      0.00        74\n",
            "           3       0.00      0.00      0.00        91\n",
            "\n",
            "    accuracy                           0.71      1150\n",
            "   macro avg       0.35      0.28      0.26      1150\n",
            "weighted avg       0.60      0.71      0.61      1150\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\CCL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\CCL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\CCL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\CCL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\CCL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\CCL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\CCL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of LogisticRegression(multi_class='multinomial', random_state=0) is 0.7234782608695652\n",
            "Confusion Matrix of LogisticRegression(multi_class='multinomial', random_state=0) is [[ 50 135   0   1]\n",
            " [ 20 779   0   0]\n",
            " [ 11  62   0   1]\n",
            " [  4  84   0   3]]\n",
            "Classificationreport is  of LogisticRegression(multi_class='multinomial', random_state=0) is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.27      0.37       186\n",
            "           1       0.73      0.97      0.84       799\n",
            "           2       0.00      0.00      0.00        74\n",
            "           3       0.60      0.03      0.06        91\n",
            "\n",
            "    accuracy                           0.72      1150\n",
            "   macro avg       0.48      0.32      0.32      1150\n",
            "weighted avg       0.65      0.72      0.65      1150\n",
            "\n",
            "Accuracy of MLPClassifier() is 0.7104347826086956\n",
            "Confusion Matrix of MLPClassifier() is [[ 82  88   8   8]\n",
            " [ 60 708  14  17]\n",
            " [ 16  39   9  10]\n",
            " [  7  59   7  18]]\n",
            "Classificationreport is  of MLPClassifier() is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.44      0.47       186\n",
            "           1       0.79      0.89      0.84       799\n",
            "           2       0.24      0.12      0.16        74\n",
            "           3       0.34      0.20      0.25        91\n",
            "\n",
            "    accuracy                           0.71      1150\n",
            "   macro avg       0.47      0.41      0.43      1150\n",
            "weighted avg       0.67      0.71      0.69      1150\n",
            "\n",
            "Accuracy of KNeighborsClassifier() is 0.6826086956521739\n",
            "Confusion Matrix of KNeighborsClassifier() is [[ 73 112   1   0]\n",
            " [ 84 712   0   3]\n",
            " [  9  65   0   0]\n",
            " [ 17  73   1   0]]\n",
            "Classificationreport is  of KNeighborsClassifier() is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.39      0.40       186\n",
            "           1       0.74      0.89      0.81       799\n",
            "           2       0.00      0.00      0.00        74\n",
            "           3       0.00      0.00      0.00        91\n",
            "\n",
            "    accuracy                           0.68      1150\n",
            "   macro avg       0.28      0.32      0.30      1150\n",
            "weighted avg       0.58      0.68      0.63      1150\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\CCL\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\CCL\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
          ]
        }
      ],
      "source": [
        "for clf in classifiers:\n",
        "    clf.fit(df_train['vec'].tolist(), y_train.tolist())\n",
        "    y_pred= clf.predict(df_val['vec'].tolist())\n",
        "    acc = accuracy_score(y_val.tolist(), y_pred)\n",
        "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
        "    cm = confusion_matrix(y_val.tolist(), y_pred)\n",
        "    print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n",
        "    report = classification_report(y_val.tolist(), y_pred)\n",
        "    print(\"Classificationreport is  of %s is %s\"%(clf, report))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSCyjdFCPOL5"
      },
      "outputs": [],
      "source": [
        "svc.fit(df_train['vec'].tolist(), y_train.tolist())\n",
        "y_pred_test= svc.predict(df_test['vec'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpgbiARuEIpS"
      },
      "outputs": [],
      "source": [
        "predct_Test=label_encoder.inverse_transform(y_pred_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2wzFcoiEIpS",
        "outputId": "7c2a0838-a820-46f3-9c3f-332998cab5b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Not Hope', 'Not Hope', 'Not Hope', ..., 'Not Hope', 'Not Hope',\n",
              "       'Not Hope'], dtype=object)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predct_Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "123YbyZsEIpS"
      },
      "outputs": [],
      "source": [
        "#Submission\n",
        "# to create .csv file consisting of tweet ids and predicted labels with CTbert\n",
        "pred_testk = pd.DataFrame(data=predct_Test, columns=['Prediction'])\n",
        "submission_t1span= pd.DataFrame()\n",
        "submission_t1span['id'] = df_test['id']\n",
        "submission_t1span['multiclass'] = pred_testk\n",
        "submission_t1span.to_csv('task2_span_Withoutoversample_aignvec_svc_46.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vgOoc9fEIpS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}